"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9738],{6643:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>r,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var n=t(5893),s=t(1151);const a={title:"Evaluate ML models",description:"sample page",custom_edit_url:"Evaluate-ML-Models"},o=void 0,l={id:"Create/Evaluate ML Models",title:"Evaluate ML models",description:"sample page",source:"@site/docs/02-Create/01-Evaluate ML Models.mdx",sourceDirName:"02-Create",slug:"/Create/Evaluate ML Models",permalink:"/solution-watsonx-governance/Create/Evaluate ML Models",draft:!1,unlisted:!1,editUrl:"Evaluate-ML-Models",tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Evaluate ML models",description:"sample page",custom_edit_url:"Evaluate-ML-Models"},sidebar:"tutorialSidebar",previous:{title:"Evaluate LLMs",permalink:"/solution-watsonx-governance/Create/Evaluate LLMs"},next:{title:"Model Lifecycle",permalink:"/solution-watsonx-governance/Create/Model Lifecycle"}},r={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Instructions",id:"instructions",level:2},{value:"<strong>Configure Model Info</strong>",id:"configure-model-info",level:3},{value:"<strong>Configure Explainability Metrics</strong>",id:"configure-explainability-metrics",level:3},{value:"<strong>Configure Evaluation Metrics (e.g. Fairness, Quality)</strong>",id:"configure-evaluation-metrics-eg-fairness-quality",level:3}];function d(e){const i={a:"a",br:"br",h2:"h2",h3:"h3",img:"img",li:"li",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.a,{href:"./AutoAI%20Experimentation",children:"Finished AutoAI Experimentation"})}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"instructions",children:"Instructions"}),"\n",(0,n.jsx)(i.h3,{id:"configure-model-info",children:(0,n.jsx)(i.strong,{children:"Configure Model Info"})}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:["Click on your model Yonce you've added the model to OpenScale. Click the blue button \u201cActions\u201d and select \u201cConfigure monitors\u201d\n",(0,n.jsx)(i.img,{src:t(8998).Z+"",width:"1470",height:"742"})]}),"\n",(0,n.jsxs)(i.li,{children:['You will see the following configuration view. Click \u201cEdit\u201d on the upper right hand corner for the "Training data" box.\n',(0,n.jsx)(i.img,{src:t(8497).Z+"",width:"930",height:"458"})]}),"\n",(0,n.jsxs)(i.li,{children:["Select \u201cUse manual setup\u201d and click \u201cNext\u201d\n",(0,n.jsx)(i.img,{src:t(7360).Z+"",width:"1332",height:"694"})]}),"\n",(0,n.jsxs)(i.li,{children:["To setup the monitoring, we would need to provide training data and specify what are the data features that we want to monitor on. For Training data option, select \u201cUpload file\u201d from the dropdown list as we will be uploading a training dataset in this example. Browse the training dataset file, select \u201cComma\u201d from the dropdown for Select delimiter, as the csv file is being separated by comma. Click \u201dNext\u201d.\n",(0,n.jsx)(i.img,{src:t(5447).Z+"",width:"892",height:"468"}),"\n",(0,n.jsx)(i.img,{src:t(6964).Z+"",width:"936",height:"494"})]}),"\n",(0,n.jsxs)(i.li,{children:["You will see this view with the data column information in the submitted training dataset. Scroll down and make sure that \u201cDecision\u201d is checked for \u201cLabel / Target\u201d as that\u2019s the targeted prediction field. Click \u201cNext\u201d\n",(0,n.jsx)(i.img,{src:t(4873).Z+"",width:"1226",height:"640"})]}),"\n",(0,n.jsxs)(i.li,{children:["Ensure the prediction and probability are clicked accordingly. Click \u201cView Summary\u201d\n",(0,n.jsx)(i.img,{src:t(4243).Z+"",width:"1226",height:"638"})]}),"\n",(0,n.jsxs)(i.li,{children:["You will see this summary view, click \u201cFinish\u201d\n",(0,n.jsx)(i.img,{src:t(2975).Z+"",width:"1224",height:"648"})]}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"configure-explainability-metrics",children:(0,n.jsx)(i.strong,{children:"Configure Explainability Metrics"})}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:["After last step in Configure Model Info section, you will now see this view with the training data attached and the data labels specified.\n",(0,n.jsx)(i.img,{src:t(8465).Z+"",width:"1666",height:"730"})]}),"\n",(0,n.jsxs)(i.li,{children:['We first configure Explanability. To configure monitoring metrics for explanability, on the left hand side panel, navigate to \u201cGeneral settings\u201d under Explainability. Click on the "Edit" icon for "Explanation method" to start configuration.',(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.img,{src:t(7963).Z+"",width:"1170",height:"592"})]}),"\n",(0,n.jsxs)(i.li,{children:["Explanation method: In our example, we will set the SHAP global explanation to \u201cOn\u201d and select \u201cSHAP\u201d for Local explanation method. Click \u201cNext\u201d.\n",(0,n.jsx)(i.img,{src:t(9734).Z+"",width:"1482",height:"770"})]}),"\n",(0,n.jsxs)(i.li,{children:["We need to select Controllable features for explanability. Controllable features are features that can be changed and have a significant impact on your model outcomes. In our example, we set all features as controllable, and click \u201cSave\u201d\n",(0,n.jsx)(i.img,{src:t(5391).Z+"",width:"1224",height:"634"})]}),"\n",(0,n.jsxs)(i.li,{children:['Once we selected "SHAP" for Explanation method, we will need to configure the SHAP tab. Navigate to the SHAP tab and click the "Edit" icon for "Common Settings" to start configuration.\n',(0,n.jsx)(i.img,{src:t(9069).Z+"",width:"1246",height:"636"})]}),"\n",(0,n.jsxs)(i.li,{children:["Set the number of perturbations per record. In our example we use the default value 0. Click \u201dSave\u201d. For more information about SHAP model, click here: ",(0,n.jsx)(i.a,{href:"https://dataplatform.cloud.ibm.com/docs/content/wsj/model/wos-explainability-config.html?context=cpdaas",children:"Configuring explainability in Watson OpenScale"}),"\n",(0,n.jsx)(i.img,{src:t(8078).Z+"",width:"1224",height:"604"})]}),"\n"]}),"\n",(0,n.jsx)(i.h3,{id:"configure-evaluation-metrics-eg-fairness-quality",children:(0,n.jsx)(i.strong,{children:"Configure Evaluation Metrics (e.g. Fairness, Quality)"})}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:["To configure Fairness, navigate to the \u201dFairness\u201d tab under Evaluations.","\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:['Click \u201cEdit\u201d icon for "Configuration" to configure the metrics. Select \u201cConfigure manually\u201d and click \u201cSave\u201d.',(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.img,{src:t(8745).Z+"",width:"938",height:"482"})]}),"\n",(0,n.jsxs)(i.li,{children:["Next, click \u201cEdit\u201d icon for Favorable outcomes to configure.\n",(0,n.jsx)(i.img,{src:t(9634).Z+"",width:"612",height:"272"})]}),"\n",(0,n.jsxs)(i.li,{children:["Configure the Favorable outcomes by selecting the checkboxes according to the use case. In our example, \u201cHired\u201d is the favorable outcome and \u201cNot_Hired\u201d is the unfavorable outcomes. Click \u201cSave\u201d.",(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.img,{src:t(9401).Z+"",width:"1024",height:"528"})]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:['Next, we configre "Sample Size". Click \u201cEdit\u201d icon for "Sample Size" to start configuration.\n',(0,n.jsx)(i.img,{src:t(573).Z+"",width:"562",height:"240"})]}),"\n",(0,n.jsxs)(i.li,{children:["Set the minimum sample size to a number equal or smaller than the testing data, in our example, we set it as 1000. Click \u201cSave\u201d.",(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.img,{src:t(5590).Z+"",width:"566",height:"776"})]}),"\n",(0,n.jsxs)(i.li,{children:['Next, click \u201cEdit\u201d icon for "Metrics" to configure Metrics.\n',(0,n.jsx)(i.img,{src:t(9878).Z+"",width:"584",height:"198"})]}),"\n",(0,n.jsxs)(i.li,{children:["Select metrics that you\u2019d like to monitor. In our example, we additionally select \u201cStatistical parity difference\u201d. Click \u201cSave\u201d.\n",(0,n.jsx)(i.img,{src:t(4124).Z+"",width:"1160",height:"596"})]}),"\n",(0,n.jsxs)(i.li,{children:["We could then set the lower and upper threshold for fairness value. In our example, we use the default value. Click \u201cSave\u201d to finish the setup.",(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.img,{src:t(7147).Z+"",width:"582",height:"792"})]}),"\n",(0,n.jsxs)(i.li,{children:["For more information about Configuring fairness evaluations, click here: ",(0,n.jsx)(i.a,{href:"https://dataplatform.cloud.ibm.com/docs/content/wsj/model/wos-monitor-fairness.html?context=cpdaas&audience=wdp",children:"Configuring fairness evaluations in Watson OpenScale"})]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,s.a)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8998:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/ClassificationModelBeforeMonitorConfig-debc116453a9a4c3d659f4c457df4be5.png"},2975:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/ClassificationModelSummary-2648cad4920a66dd66b695142fde74aa.png"},8745:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/FairnessConfig-129f1f2fd752605b5254feb804c68e21.png"},7147:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/FairnessDisparateImpact-8b437de09cca61217943faa2c27b569e.png"},9634:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/FairnessFavorableOutcomes-ba42dbb81d000423e5be4075a43b11ff.png"},4124:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/FairnessMonitoredMetrics-f8047b361213c98841958db072aa706b.png"},7360:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MLModelConfigureMonitorMethod-a232a92390c892cd3304f20d1785435b.png"},8497:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MLModelConfigureMonitorModelDetails-49151958bdf01a4b3b7716e5039d9bb9.png"},8465:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MLModelConfigureTrainingData-ea807f1603dd4759cf6ed5173a860d8c.png"},7963:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MLModelExplanationConfig-618053a122806c814e0e7f5a88cb949d.png"},5391:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MLModelExplanationControllableFeatures-c4838eb93cb687f5a09ae4775cbb9040.png"},9734:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MLModelExplanationMethodConfig-966e7724aede941a79c37b594c2a9b9f.png"},9878:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/MetricsConfig-fa02f474239f939c63087fbb184a5daa.png"},8078:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SHAPCommonSettings-8fafc6a1ec91303df242c1280a8e149c.png"},9069:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SHAPConfig-f6df817ad803492ba78733a0e26cd513.png"},573:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SampleSizeConfig-245f58ee3c3342cdb870779112f30007.png"},5590:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SampleSizeConfig2-43bed91903e06a1a7fe24e37f30a0cb2.png"},9401:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SelectFavorableOutcomes-0e5a5c7335230d4465e54f60fc21ad5c.png"},4243:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SelectModelOutput-a9d7c9d2b38b46dd92dcbb9b433ef1a6.png"},6964:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SpecifyTrainingData2-bcbf8aa76deabc4782b814161c659df5.png"},4873:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SpecifyTrainingDataFeaturesAndLabels-79639028d6849cd660040fc94946ebb5.png"},5447:(e,i,t)=>{t.d(i,{Z:()=>n});const n=t.p+"assets/images/SpecifyTraningData-a3be83c4953385536589e3d88793018e.png"},1151:(e,i,t)=>{t.d(i,{Z:()=>l,a:()=>o});var n=t(7294);const s={},a=n.createContext(s);function o(e){const i=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(a.Provider,{value:i},e.children)}}}]);